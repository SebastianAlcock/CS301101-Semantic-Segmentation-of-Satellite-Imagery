### Nicholas Gutierrez & Sebastian Alcock
### CS301-101 - Introduction to Data Science
### November 20th, 2022

# Milestone 3: Semantic Segmentation of Satellite Imagery

#### The goal of Milestone 3 was to improve the results of our baseline semantic segmentation by performing hyperparameter optimization to find parameter values that give us the best results. When it comes to hyperparameter optimization, there are many methods. For Milestone 3, our group was assigned the TPE method. TPE stands for tree-structured parzen estimator. It works by first defining a search space and setting up a function to take in parameters and output a value we want to maximize, either loss or accuracy. This function is run multiple times with random hyperparameters, and the scores are separated into two groups, one based on the best values and the other based on the total values, we will call these groups x1 and x2 respectfully. Next, the method uses parzen estimators to create two densities we’ll call l(x1) and g(x2). We then create hyperparameters by evaluating l(x1)/g(x2). We decide which hyperparameters are best by selecting the smallest number under the function l(x1)/g(x1). After performing a successful experiment involving TPE, our optimized hyperparameters can be utilized in our model from the previous milestone to produce different results. And in our case, we decided to maximize accuracy.

#### In order to obtain an optimized set of hyperparameters, we first ran a successful experiment using NNI. In order to accomplish a successful NNI experiment, we first created a file containing the framework from the model we used for Milestone 2. We named this file ‘model.py’ and filled it with modified code from the given simple_multi_unet_model.py file utilized in Milestone 2. The file was also modified to contain code from both Milestones 1 and 2 that allow the experiment to segment and patchify the given image dataset, and fit the model framework for testing and validation. With this framework in place, our model.py file is then capable of being run with any specified set of parameters, allowing multiple trials to be run from an experiment. After this, we defined the hyperparameters we wanted to tune: learning rate, batch size, and activation type. We also additionally considered tuning the dropout rate, and in fact, did implement our model to optimize this parameter, however, Google colab is difficult to work with when using extremely large search spaces due to limited RAM and performance, so we stuck to the three we felt were most important. Next, we modified our model.py to create, compile, and fit the model in order to display the figure we wanted our TPE tuner to optimize, that being the accuracy. Finally, in order to properly run the experiment, we created a new NNI experiment with specific configurations for search space using our hyperparameters, the TPE optimization method, the number and type of trials, and our model.py file to be run. In order to view these trials, using our knowledge from Milestone 1, we created a ngrok link to our local NNI experiment’s webpage to graph the results of each parameter trial and view the resulting optimization for our selected hyperparameters.

###### Our NNI Experiment's final overall results as seen from our NNI UI:
![unknow1n](https://user-images.githubusercontent.com/78321301/202931559-ccc3a778-b9bd-4795-8c7e-d391c143d6bb.png)
###### Our NNI Experiment's intermediate results:
![unknown](https://user-images.githubusercontent.com/78321301/202931562-78b9e238-b1b2-4e39-9044-17d55bdbf042.png)

#### After running the experiment, we can see that the best parameters for our semantic segmentation are a batch size of 4, activation type ‘relu’, and a learning rate of 0.0004678418249479461. Putting these parameters into our model and running the calculations, we can better our performance outputting generally improved values and prediction images. Over 100 epochs, our loss decreased from around 90% to 88%, meaning that our model is more reliable now. Our accuracy, the output we wanted to maximize, rose from around 89% to 93%, and the jacquard coefficient went from 77% to 85%, all through our use of the newly optimized parameters. As our accuracy was the output we wanted to maximize, the graph of our IoU saw the most improvement, moving to nearly 90%; and our mean IoU saw an overall increase, demonstrating increased consistency in lining up predictions. Additionally, our precision-recall curve also saw a reduced drop at the start of the graph compared to the baseline performance and a more stable precision across runtime, signifying that our program is now generally more consistent. The prediction images look very similar to the color masks and in some cases outline structures that the original mask did not, improving upon our previous results as well as the masks themselves. Overall, optimizing hyperparameters allowed our program to become more consistent in all categories while slightly improving our results, especially when it comes to accuracy and IOU.

###### Optimized results for Loss, IOU, and Precision-Recall:
![d32be6861d3653ea3fea5d5bab2cefc8](https://user-images.githubusercontent.com/78321301/202931446-c4f8e69f-d054-469a-961a-0db8ff0b4321.png)
###### Ten segmented image examples from our optimized model:
![6ffc08d633a3097f6c6d3da547c0b726](https://user-images.githubusercontent.com/78321301/202931449-156795f7-a6b8-43cc-979e-eee2f6c813a6.png)
![55adbe744a195ca505edb0c617a4b107](https://user-images.githubusercontent.com/78321301/202931452-1fe148b9-0485-450d-9839-afdd1d3e84a8.png)
![ab1a62ad2ec0806350eafb18c2091a2c](https://user-images.githubusercontent.com/78321301/202931455-b59a0722-bd18-4d3d-b223-c3d90ce4d2d1.png)
![6be8b388cb17da78e136bc5ffed4c0ad](https://user-images.githubusercontent.com/78321301/202931457-23de9f64-1fd1-45fd-8eed-545fd31a1ad4.png)

#### Our group faced multiple challenges within this Milestone. Our greatest difficulty revolved around successfully creating our model.py file and running the NNI experiment. Initially, our code had errors when creating the model since we relied on functions and file pathways from the simple_multi_unet_model file and Milestone 2, which the new local experiment could not access. This forced us to include it ourselves, in addition to redefining any functions we needed to utilize for our experiment. Other issues also came from the experiment frequently crashing, which we had to utilize the NNI experiment logs to investigate. Often, the interface would tell us it was due to running out of memory, so we had to review our code to see where we could be causing these issues. Eventually, we resolved this by properly defining a limited search space, reporting our loss and accuracy, and granting our experiment proper access to colab’s GPU. 

#### Overall, in this Milestone, we optimized our hyperparameters parameters and produced more effective results. Our final steps going forward will be to compress our model and its memory usage so our model will produce decent results even on machines that don't have advanced accelerators, such as colab’s Premium GPU, or high memory available.
